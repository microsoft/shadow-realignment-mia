{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests of the various re-alignment techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '../../')\n",
    "import src.align\n",
    "importlib.reload(src.align)\n",
    "from src.align import (BottomUpAlignmentMethod,\n",
    "    TopDownAlignmentMethod,\n",
    "    TopDownWeightMatchingBasedAlignment,\n",
    "    WeightSortingBasedAlignment,\n",
    "    BottomUpWeightMatchingBasedAlignment, \n",
    "    BottomUpActivationMatchingBasedAlignment,\n",
    "    TopDownActivationMatchingBasedAlignment,\n",
    "    BottomUpCorrelationMatchingBasedAlignment,\n",
    "    GreedyMatching, \n",
    "    HungarianAlgorithmMatching)\n",
    "from src.models import CNNLarge, GenericMLP\n",
    "\n",
    "torch.set_printoptions(precision=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3072])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "records = torch.normal(size=(5, 3, 32, 32), mean=0, std=1)\n",
    "records_flattened = torch.flatten(records, 1)\n",
    "print(records_flattened.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first test that re-alignment works for the identity permutation. We test that the outputs of the model remain the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.conv1[0].weight.size(), model.conv2[0].weight.size(), model.fc1[0].weight.size())\n",
    "\n",
    "print(model(records))\n",
    "\n",
    "a1 = BottomUpAlignmentMethod()\n",
    "aligned_model = a1.align_layers(model, sorted_idxs={'conv1': np.arange(20), 'conv2': np.arange(50), 'fc1': np.arange(500)})\n",
    "\n",
    "print(aligned_model(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Generic MLP. The output should stay the same whether we apply the identity permutation or a different permutation. The weights should stay the same when we apply the identity permutation but should be permuted accordingly when we apply a different permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0292731617, -0.5151621699],\n",
      "        [-0.0294966158, -0.5110382438],\n",
      "        [-0.0295566171, -0.5099309087],\n",
      "        [-0.0296777636, -0.5076951385],\n",
      "        [-0.0292622689, -0.5153631568]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0113725066,  0.0048179408, -0.0048890654], grad_fn=<SliceBackward0>)\n",
      "tensor([0.1931403130, 0.1464328617, 0.2207494080], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0292731617, -0.5151621699],\n",
      "        [-0.0294966158, -0.5110382438],\n",
      "        [-0.0295566171, -0.5099309087],\n",
      "        [-0.0296777636, -0.5076951385],\n",
      "        [-0.0292622689, -0.5153631568]], grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0113725066,  0.0048179408, -0.0048890654], grad_fn=<SliceBackward0>)\n",
      "tensor([0.1931403130, 0.1464328617, 0.2207494080], grad_fn=<SliceBackward0>)\n",
      "tensor([ 0.0048179408, -0.0113725066, -0.0048890654], grad_fn=<SliceBackward0>)\n",
      "tensor([0.1464328617, 0.1931403130, 0.2207494080], grad_fn=<SliceBackward0>)\n",
      "tensor([[-0.0292731617, -0.5151621699],\n",
      "        [-0.0294966158, -0.5110382438],\n",
      "        [-0.0295566171, -0.5099309087],\n",
      "        [-0.0296777636, -0.5076951385],\n",
      "        [-0.0292622689, -0.5153631568]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = GenericMLP(layer_sizes=(3072, 7, 6, 5, 4, 3, 2))\n",
    "model.eval()\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print(model(records_flattened))\n",
    "print(model.fc1.linear.bias[:3])\n",
    "print(model.fc2.linear.weight[0, :3])\n",
    "\n",
    "a1 = BottomUpAlignmentMethod()\n",
    "aligned_model = a1.align_layers(model, sorted_idxs={'fc1': np.arange(7), 'fc2': np.arange(6), 'fc3': np.arange(5),\\\n",
    "    'fc4': np.arange(4), 'fc5': np.arange(3)})\n",
    "\n",
    "print(aligned_model(records_flattened))\n",
    "print(aligned_model.fc1.linear.bias[:3])\n",
    "print(aligned_model.fc2.linear.weight[0, :3])\n",
    "\n",
    "permutation = np.arange(7)\n",
    "permutation[0] = 1\n",
    "permutation[1] = 0\n",
    "aligned_model = a1.align_layers(model, sorted_idxs={'fc1': permutation, 'fc2': np.arange(6), 'fc3': np.arange(5),\\\n",
    "    'fc4': np.arange(4), 'fc5': np.arange(3)})\n",
    "print(aligned_model.fc1.linear.bias[:3])\n",
    "print(aligned_model.fc2.linear.weight[0, :3])\n",
    "\n",
    "print(aligned_model(records_flattened))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test that re-alignment works for custom, user-defined permutations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Applying a permutation to the first layer only.\n",
      "tensor([[ 0.0742715523,  0.1782564074,  0.0600745901],\n",
      "        [ 0.1083159596,  0.1627133787,  0.0658591017],\n",
      "        [ 0.1604914814,  0.2382882684, -0.0252837837],\n",
      "        [ 0.0827142075,  0.1198018044,  0.0181518812],\n",
      "        [ 0.1977792531,  0.2047205418, -0.0100920498]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[18  1 19  8 10 17  6 13  4  2  5 14  9  7 16 11  3  0 15 12] tensor([ 0.0042774230,  0.0423303209,  0.0014932797,  0.0381272994,\n",
      "         0.0768987313,  0.0132682649,  0.0619851127, -0.0603320338,\n",
      "         0.1004339606,  0.0463842377, -0.0808997974, -0.0208789352,\n",
      "         0.0420578122,  0.0099556111, -0.0741394907, -0.0082215518,\n",
      "        -0.1138258949,  0.0782932863,  0.0609183162, -0.0550695248],\n",
      "       grad_fn=<SelectBackward0>) tensor([ 0.0609183162,  0.0423303209, -0.0550695248,  0.1004339606,\n",
      "        -0.0808997974,  0.0782932863,  0.0619851127,  0.0099556111,\n",
      "         0.0768987313,  0.0014932797,  0.0132682649, -0.0741394907,\n",
      "         0.0463842377, -0.0603320338, -0.1138258949, -0.0208789352,\n",
      "         0.0381272994,  0.0042774230, -0.0082215518,  0.0420578122],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "[18  1 19  8 10 17  6 13  4  2  5 14  9  7 16 11  3  0 15 12] Parameter containing:\n",
      "tensor([ 0.0931478292, -0.0902533308,  0.0397556275, -0.0434939526,\n",
      "        -0.0485915691, -0.0240835622, -0.0427407697,  0.0632729903,\n",
      "        -0.0219392069,  0.0875514373,  0.0263483208, -0.0178418867,\n",
      "        -0.0666954368, -0.1057328135, -0.0336851887, -0.1069289148,\n",
      "        -0.0213932134,  0.0018872782, -0.0074413321, -0.0567208417],\n",
      "       requires_grad=True) Parameter containing:\n",
      "tensor([-0.0074413321, -0.0902533308, -0.0567208417, -0.0219392069,\n",
      "         0.0263483208,  0.0018872782, -0.0427407697, -0.1057328135,\n",
      "        -0.0485915691,  0.0397556275, -0.0240835622, -0.0336851887,\n",
      "         0.0875514373,  0.0632729903, -0.0213932134, -0.0178418867,\n",
      "        -0.0434939526,  0.0931478292, -0.1069289148, -0.0666954368],\n",
      "       requires_grad=True)\n",
      "Applying a permutation to the second layer only.\n",
      "tensor([[ 0.0742715374,  0.1782564223,  0.0600745827],\n",
      "        [ 0.1083159447,  0.1627133936,  0.0658591315],\n",
      "        [ 0.1604915559,  0.2382882684, -0.0252837315],\n",
      "        [ 0.0827141777,  0.1198017746,  0.0181518067],\n",
      "        [ 0.1977791488,  0.2047205418, -0.0100920722]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Applying a permutation to the third layer only.\n",
      "tensor([[ 0.0742715597,  0.1782564223,  0.0600745603],\n",
      "        [ 0.1083159596,  0.1627133787,  0.0658591166],\n",
      "        [ 0.1604915410,  0.2382883579, -0.0252836868],\n",
      "        [ 0.0827141926,  0.1198018119,  0.0181517676],\n",
      "        [ 0.1977791935,  0.2047205120, -0.0100920722]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Applying a permutation to all the layers.\n",
      "tensor([[ 0.0742715076,  0.1782563627,  0.0600744970],\n",
      "        [ 0.1083159596,  0.1627133936,  0.0658590645],\n",
      "        [ 0.1604915410,  0.2382882982, -0.0252837017],\n",
      "        [ 0.0827141702,  0.1198018789,  0.0181518737],\n",
      "        [ 0.1977791935,  0.2047205418, -0.0100920238]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.conv1[0].weight.size(), model.conv2[0].weight.size(), model.fc1[0].weight.size())\n",
    "\n",
    "print(model(records))\n",
    "\n",
    "a2 = BottomUpAlignmentMethod()\n",
    "print('Applying a permutation to the first layer only.')\n",
    "permutation = np.random.permutation(20)\n",
    "aligned_model = a2.align_layers(model, sorted_idxs={'conv1': permutation, 'conv2': np.arange(50), 'fc1': np.arange(500)})\n",
    "\n",
    "print(aligned_model(records))\n",
    "\n",
    "print(permutation, model.conv1[0].weight[:, 0, 3, 0], aligned_model.conv1[0].weight[:, 0, 3, 0])\n",
    "print(permutation, model.conv1[0].bias, aligned_model.conv1[0].bias)\n",
    "\n",
    "a3 = BottomUpAlignmentMethod()\n",
    "print('Applying a permutation to the second layer only.')\n",
    "aligned_model = a3.align_layers(model, sorted_idxs={'conv1': np.arange(20), 'conv2': np.random.permutation(50), 'fc1': np.arange(500)})\n",
    "\n",
    "print(aligned_model(records))\n",
    "\n",
    "a4 = BottomUpAlignmentMethod()\n",
    "print('Applying a permutation to the third layer only.')\n",
    "aligned_model = a4.align_layers(model, sorted_idxs={'conv1': np.arange(20), 'conv2': np.arange(50), 'fc1': np.random.permutation(500)})\n",
    "\n",
    "print(aligned_model(records))\n",
    "\n",
    "a5 = BottomUpAlignmentMethod()\n",
    "print('Applying a permutation to all the layers.')\n",
    "aligned_model = a5.align_layers(model, sorted_idxs={'conv1': np.random.permutation(20), 'conv2': np.random.permutation(50), 'fc1': np.random.permutation(500)})\n",
    "\n",
    "print(aligned_model(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the permutations work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0008645035,  0.1018857807, -0.1080628857,  0.0572013110,\n",
      "        -0.0557106063, -0.0655576065,  0.0957626626, -0.0586115047,\n",
      "        -0.0974088088,  0.0886598602, -0.0928521156, -0.0195688419,\n",
      "         0.0966262743,  0.0099808285, -0.0217446089, -0.0162298270,\n",
      "         0.0490856394, -0.0343011618, -0.0517730713,  0.0110124676],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([[ 0.0742716193,  0.1782564223,  0.0600745529],\n",
      "        [ 0.1083159745,  0.1627133787,  0.0658591986],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837166],\n",
      "        [ 0.0827142149,  0.1198017746,  0.0181517489],\n",
      "        [ 0.1977792084,  0.2047205120, -0.0100920610]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0008645035,  0.1018857807, -0.1080628857,  0.0572013110,\n",
      "        -0.0557106063, -0.0655576065,  0.0957626626, -0.0586115047,\n",
      "        -0.0974088088,  0.0886598602, -0.0928521156, -0.0195688419,\n",
      "         0.0966262743,  0.0099808285, -0.0217446089, -0.0162298270,\n",
      "         0.0490856394, -0.0343011618, -0.0517730713,  0.0110124676],\n",
      "       grad_fn=<SelectBackward0>) tensor([ 0.1018857807, -0.0008645035, -0.1080628857,  0.0572013110,\n",
      "        -0.0557106063, -0.0655576065,  0.0957626626, -0.0586115047,\n",
      "        -0.0974088088,  0.0886598602, -0.0928521156, -0.0195688419,\n",
      "         0.0966262743,  0.0099808285, -0.0217446089, -0.0162298270,\n",
      "         0.0490856394, -0.0343011618, -0.0517730713,  0.0110124676],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 3.1039472669e-02,  3.5504695028e-02, -4.1668098420e-02,\n",
      "         2.1113158436e-04,  6.3483952545e-05, -4.0466486826e-04,\n",
      "         1.9896199927e-02,  4.3444186449e-02,  3.5952754319e-02,\n",
      "        -1.1799298227e-02, -2.6850841939e-02, -1.1605967768e-02,\n",
      "        -1.1995603330e-02, -3.5810071975e-02,  3.8079764694e-02,\n",
      "        -1.4774822630e-02, -1.3721532188e-02,  1.7448564991e-02,\n",
      "        -4.0739282966e-02,  2.7282919735e-02], grad_fn=<SelectBackward0>) tensor([ 3.5504695028e-02,  3.1039472669e-02, -4.1668098420e-02,\n",
      "         2.1113158436e-04,  6.3483952545e-05, -4.0466486826e-04,\n",
      "         1.9896199927e-02,  4.3444186449e-02,  3.5952754319e-02,\n",
      "        -1.1799298227e-02, -2.6850841939e-02, -1.1605967768e-02,\n",
      "        -1.1995603330e-02, -3.5810071975e-02,  3.8079764694e-02,\n",
      "        -1.4774822630e-02, -1.3721532188e-02,  1.7448564991e-02,\n",
      "        -4.0739282966e-02,  2.7282919735e-02], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.conv1[0].weight.size(), model.conv2[0].weight.size(), model.fc1[0].weight.size())\n",
    "\n",
    "print(model(records))\n",
    "print(model.conv1[0].weight[:, 0, 0, 0])\n",
    "\n",
    "a6 = BottomUpAlignmentMethod()\n",
    "permutation = np.arange(20)\n",
    "permutation[1] = 0\n",
    "permutation[0] = 1\n",
    "aligned_model = a6.align_layers(model, sorted_idxs={'conv1': permutation, 'conv2': np.arange(50), 'fc1': np.arange(500)})\n",
    "\n",
    "print(aligned_model(records))\n",
    "print(model.conv1[0].weight[:, 0, 0, 0], aligned_model.conv1[0].weight[:, 0, 0, 0])\n",
    "print(model.conv2[0].weight[0, :, 0, 0], aligned_model.conv2[0].weight[0, :, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test that the weight sorting-based alignment works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0742715597,  0.1782563776,  0.0600745790],\n",
      "        [ 0.1083160043,  0.1627133638,  0.0658590943],\n",
      "        [ 0.1604915559,  0.2382882684, -0.0252837464],\n",
      "        [ 0.0827142298,  0.1198018342,  0.0181518402],\n",
      "        [ 0.1977792233,  0.2047205418, -0.0100920498]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Order before tensor([-0.0668168366, -0.5240811110, -0.7045913935, -0.3533548117,\n",
      "         0.4629522562,  0.4145592451,  0.3347054124, -0.0400037766,\n",
      "        -0.1369437724,  0.2329905033,  0.1089634970,  0.4734973907,\n",
      "         0.0717745423, -0.3839237094, -0.7761198878, -0.9724586010,\n",
      "         0.1650214642, -0.0117033869,  0.8463528752, -0.1195361614],\n",
      "       grad_fn=<SumBackward1>)\n",
      "Order after tensor([-0.9724586010, -0.7761198878, -0.7045913935, -0.5240811110,\n",
      "        -0.3839237094, -0.3533548117, -0.1369437724, -0.1195361614,\n",
      "        -0.0668168366, -0.0400037766, -0.0117033869,  0.0717745423,\n",
      "         0.1089634970,  0.1650214642,  0.2329905033,  0.3347054124,\n",
      "         0.4145592451,  0.4629522562,  0.4734973907,  0.8463528752],\n",
      "       grad_fn=<SumBackward1>)\n",
      "Order before tensor([ 0.8124563098,  0.3859703541,  0.1565654874,  0.0067591220,\n",
      "        -0.0730455145,  0.1821246892, -0.9942302704, -0.1024446785,\n",
      "         0.1595724225, -0.4974681139], grad_fn=<SliceBackward0>)\n",
      "Order after tensor([-1.6038213968, -1.4421585798, -1.3654274940, -1.3145456314,\n",
      "        -1.2658789158, -1.2276132107, -1.2239077091, -1.2067250013,\n",
      "        -1.2034815550, -1.2009093761], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.conv1[0].weight.size(), model.conv2[0].weight.size(), model.fc1[0].weight.size())\n",
    "\n",
    "print(model(records))\n",
    "\n",
    "a7 = WeightSortingBasedAlignment()\n",
    "aligned_model = a7.align_layers(model)\n",
    "\n",
    "print(aligned_model(records))\n",
    "print('Order before', model.conv1[0].weight.view(model.conv1[0].weight.size(0), -1).sum(dim=1))\n",
    "print('Order after', aligned_model.conv1[0].weight.view(aligned_model.conv1[0].weight.size(0), -1).sum(dim=1))\n",
    "\n",
    "print('Order before', model.fc1.linear.weight.view(model.fc1.linear.weight.size(0), -1).sum(dim=1)[:10])\n",
    "print('Order after', aligned_model.fc1.linear.weight.view(aligned_model.fc1.linear.weight.size(0), -1).sum(dim=1)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same test for the GenericMLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0292731617, -0.5151621699],\n",
      "        [-0.0294966158, -0.5110382438],\n",
      "        [-0.0295566171, -0.5099309087],\n",
      "        [-0.0296777636, -0.5076951385],\n",
      "        [-0.0292622689, -0.5153631568]], grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0292731617, -0.5151621699],\n",
      "        [-0.0294966158, -0.5110382438],\n",
      "        [-0.0295566171, -0.5099309087],\n",
      "        [-0.0296777636, -0.5076951385],\n",
      "        [-0.0292622689, -0.5153631568]], grad_fn=<AddmmBackward0>)\n",
      "Order before tensor([-0.2159837186, -0.3019032180,  0.7937227488,  0.4051253796,\n",
      "         0.1338184774,  0.5888521671, -0.0695017725], grad_fn=<SumBackward1>)\n",
      "Order after tensor([-0.3019032180, -0.2159837186, -0.0695017725,  0.1338184774,\n",
      "         0.4051253796,  0.5888521671,  0.7937227488], grad_fn=<SumBackward1>)\n",
      "Order before tensor([ 0.0541683435, -0.3083331585,  0.5434048176,  0.2548643947,\n",
      "        -0.4114866853,  0.6938853860], grad_fn=<SumBackward1>)\n",
      "Order after tensor([-0.4114866853, -0.3083331585,  0.0541683435,  0.2548644543,\n",
      "         0.5434048772,  0.6938854456], grad_fn=<SumBackward1>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = GenericMLP(layer_sizes=(3072, 7, 6, 5, 4, 3, 2))\n",
    "model.eval()\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print(model(records_flattened))\n",
    "\n",
    "a7 = WeightSortingBasedAlignment()\n",
    "aligned_model = a7.align_layers(model)\n",
    "\n",
    "print(aligned_model(records_flattened))\n",
    "print('Order before', model.fc1.linear.weight.view(7, -1).sum(dim=1))\n",
    "print('Order after', aligned_model.fc1.linear.weight.view(7, -1).sum(dim=1))\n",
    "\n",
    "print('Order before', model.fc2.linear.weight.view(6, -1).sum(dim=1))\n",
    "print('Order after', aligned_model.fc2.linear.weight.view(6, -1).sum(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test that the matching techniques work as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 1. 0.]\n",
      "[2 0 1]\n",
      "[0. 1. 2.]\n",
      "[0 1 2]\n"
     ]
    }
   ],
   "source": [
    "greedy_matching = GreedyMatching()\n",
    "\n",
    "hungarian_matching = HungarianAlgorithmMatching()\n",
    "\n",
    "print(greedy_matching.match(torch.FloatTensor([\n",
    "    [2, 1, 0.01],\n",
    "    [3, 4, 5],\n",
    "    [0.05, 0.1, 0.15]])))\n",
    "    \n",
    "print(hungarian_matching.match(torch.FloatTensor([\n",
    "    [2, 1, 0.01],\n",
    "    [3, 4, 5],\n",
    "    [0.05, 0.1, 0.15]])))\n",
    "\n",
    "print(greedy_matching.match(torch.FloatTensor([\n",
    "    [0.1, 3, 1],\n",
    "    [5, 4, 3.5],\n",
    "    [4, 4, 3]])))\n",
    "\n",
    "print(hungarian_matching.match(torch.FloatTensor([\n",
    "    [0.1, 3, 1],\n",
    "    [5, 4, 3.5],\n",
    "    [4, 4, 3]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test that weight matching-based re-alignment works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "I am here\n",
      "tensor([[ 0.0742714852,  0.1782564223,  0.0600746609],\n",
      "        [ 0.1083159596,  0.1627133489,  0.0658590943],\n",
      "        [ 0.1604915857,  0.2382882833, -0.0252837464],\n",
      "        [ 0.0827142000,  0.1198017746,  0.0181518532],\n",
      "        [ 0.1977791190,  0.2047205269, -0.0100920610]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[0.00026345252990722656, 0.0006096363067626953, 0.026691436767578125]\n",
      "I am here\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[6.341934204101562e-05, 0.00014543533325195312, 0.015626192092895508]\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model1, model2 = CNNLarge(3), CNNLarge(3)\n",
    "model1.eval(), model2.eval()\n",
    "\n",
    "print('Model layer sizes', model1.conv1[0].weight.size(), model1.conv2[0].weight.size(), model1.fc1[0].weight.size())\n",
    "\n",
    "print(model1(records))\n",
    "\n",
    "a8 = BottomUpWeightMatchingBasedAlignment(GreedyMatching())\n",
    "aligned_model1 = a8.align_layers(model1, model2)\n",
    "\n",
    "print(aligned_model1(records))\n",
    "print(a8.elapsed_times)\n",
    "\n",
    "a8bis = BottomUpWeightMatchingBasedAlignment(HungarianAlgorithmMatching())\n",
    "a8bis.align_layers(model1, model2)\n",
    "\n",
    "print(model1(records))\n",
    "print(a8bis.elapsed_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0988133550, -0.0700098723, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039329, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146526, -0.1857692599],\n",
      "        [-0.0992155895, -0.0657143146, -0.1859866083],\n",
      "        [-0.0967054814, -0.0699071437, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "I am here\n",
      "tensor([[-0.0988133550, -0.0700098723, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039478, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146600, -0.1857692599],\n",
      "        [-0.0992155895, -0.0657143220, -0.1859866083],\n",
      "        [-0.0967054963, -0.0699071512, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0988133550, -0.0700098723, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039478, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146451, -0.1857692748],\n",
      "        [-0.0992155895, -0.0657143220, -0.1859866083],\n",
      "        [-0.0967054889, -0.0699071437, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model1 = GenericMLP(layer_sizes=(3072, 70, 60, 50, 40, 30, 3))\n",
    "model2 = GenericMLP(layer_sizes=(3072, 70, 60, 50, 40, 30, 3))\n",
    "model1.eval(), model2.eval()\n",
    "\n",
    "#print(model)\n",
    "\n",
    "#print(model2(records_flattened))\n",
    "print(model1(records_flattened))\n",
    "\n",
    "a9 = BottomUpWeightMatchingBasedAlignment(HungarianAlgorithmMatching())\n",
    "aligned_model1 = a9.align_layers(model1, model2)\n",
    "\n",
    "print(aligned_model1(records_flattened))\n",
    "\n",
    "a10 = BottomUpCorrelationMatchingBasedAlignment(HungarianAlgorithmMatching())\n",
    "aligned_model2 = a10.align_layers(model1, model2, records=records_flattened)\n",
    "\n",
    "print(aligned_model2(records_flattened))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test that activation-based matching works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0063933060,  0.0175652150,  0.0109577179,  0.0020585060,\n",
      "         0.0131788002, -0.0199355874,  0.0182594843,  0.0087319063,\n",
      "         0.0174824577,  0.0227316059], grad_fn=<SliceBackward0>)\n",
      "tensor([[ 0.0742715448,  0.1782563180,  0.0600745678],\n",
      "        [ 0.1083159745,  0.1627133042,  0.0658590719],\n",
      "        [ 0.1604914963,  0.2382882386, -0.0252837762],\n",
      "        [ 0.0827142373,  0.1198018119,  0.0181519128],\n",
      "        [ 0.1977791488,  0.2047205418, -0.0100920498]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "[9.775161743164062e-05, 0.0001761913299560547, 0.02301645278930664]\n",
      "tensor([ 0.0182594843, -0.0178919714, -0.0231268890,  0.0013742030,\n",
      "         0.0087319063, -0.0089161014,  0.0183514412,  0.0227316059,\n",
      "        -0.0266217533,  0.0165754482], grad_fn=<SliceBackward0>)\n",
      "Parameter containing:\n",
      "tensor([ 0.0931478292, -0.0902533308,  0.0397556275, -0.0434939526,\n",
      "        -0.0485915691, -0.0240835622, -0.0427407697,  0.0632729903,\n",
      "        -0.0219392069,  0.0875514373,  0.0263483208, -0.0178418867,\n",
      "        -0.0666954368, -0.1057328135, -0.0336851887, -0.1069289148,\n",
      "        -0.0213932134,  0.0018872782, -0.0074413321, -0.0567208417],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0018872782, -0.0219392069, -0.0240835622, -0.0336851887,\n",
      "        -0.0434939526, -0.0178418867,  0.0931478292, -0.0213932134,\n",
      "        -0.0666954368, -0.0427407697, -0.1069289148,  0.0397556275,\n",
      "        -0.1057328135,  0.0632729903, -0.0074413321, -0.0485915691,\n",
      "         0.0875514373, -0.0567208417,  0.0263483208, -0.0902533308],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model1, model2 = CNNLarge(3), CNNLarge(3)\n",
    "model1.eval(), model2.eval()\n",
    "\n",
    "print('Model layer sizes', model1.conv1[0].weight.size(), model1.conv2[0].weight.size(), model1.fc1[0].weight.size())\n",
    "\n",
    "print(model1(records))\n",
    "biases_before = set(model1.fc1.linear.bias.tolist())\n",
    "print(model1.fc1.linear.bias[:10])\n",
    "\n",
    "a10 = BottomUpActivationMatchingBasedAlignment(HungarianAlgorithmMatching())\n",
    "#print(records)\n",
    "aligned_model1 = a10.align_layers(model1, model2, records=records)\n",
    "\n",
    "print(aligned_model1(records))\n",
    "print(a10.elapsed_times)\n",
    "\n",
    "biases_after = set(aligned_model1.fc1.linear.bias.tolist())\n",
    "\n",
    "assert len(biases_before.intersection(biases_after)) == len(biases_after)\n",
    "print(aligned_model1.fc1.linear.bias[:10])\n",
    "\n",
    "print(model1.conv1[0].bias)\n",
    "print(aligned_model1.conv1[0].bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the top-down alignment\n",
    "\n",
    "Testing that the identity permutation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes 500 50 20\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.fc1[0].weight.size(0), model.conv2[0].weight.size(0), model.conv1[0].weight.size(0))\n",
    "\n",
    "print(model(records))\n",
    "\n",
    "t1 = TopDownAlignmentMethod()\n",
    "aligned_model = t1.align_layers(model, sorted_idxs={'fc2': np.arange(500), 'fc1': np.arange(50), 'conv2': np.arange(20)})\n",
    "\n",
    "print(aligned_model(records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing that a custom permutation permutation works as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0742715597,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591315],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920573]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0216782764, -0.0295759179, -0.0382286869,  0.0249514319],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0295759179, -0.0216782764, -0.0382286869,  0.0249514319],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([ 0.0266703460,  0.0243966989, -0.0170943607, -0.0203894544],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0243966989,  0.0266703460, -0.0170943607, -0.0203894544],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.conv1[0].weight.size(), model.conv2[0].weight.size(), model.fc1[0].weight.size())\n",
    "\n",
    "print(model(records))\n",
    "\n",
    "t2 = TopDownAlignmentMethod()\n",
    "permutation = np.arange(500)\n",
    "permutation[1] = 0\n",
    "permutation[0] = 1\n",
    "aligned_model = t2.align_layers(model, sorted_idxs={'fc2': permutation, 'fc1': np.arange(50), 'conv2': np.arange(20)})\n",
    "\n",
    "print(aligned_model(records))\n",
    "print(model.fc2.linear.weight[0, :4])\n",
    "print(aligned_model.fc2.linear.weight[0, :4])\n",
    "\n",
    "print(model.fc1.linear.weight[:4, 0])\n",
    "print(aligned_model.fc1.linear.weight[:4, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model layer sizes torch.Size([20, 3, 5, 5]) torch.Size([50, 20, 5, 5]) torch.Size([500, 1250])\n",
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0742715523,  0.1782563627,  0.0600746237],\n",
      "        [ 0.1083159745,  0.1627133042,  0.0658590123],\n",
      "        [ 0.1604914963,  0.2382882982, -0.0252837986],\n",
      "        [ 0.0827142969,  0.1198018044,  0.0181518570],\n",
      "        [ 0.1977792233,  0.2047205865, -0.0100920610]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model = CNNLarge(3)\n",
    "model.eval()\n",
    "\n",
    "print('Model layer sizes', model.conv1[0].weight.size(), model.conv2[0].weight.size(), model.fc1[0].weight.size())\n",
    "\n",
    "print(model(records))\n",
    "\n",
    "t3 = TopDownAlignmentMethod()\n",
    "aligned_model = t3.align_layers(model, sorted_idxs={'fc2': np.random.permutation(500), \\\n",
    "    'fc1': np.random.permutation(50), 'conv2': np.random.permutation(20)})\n",
    "\n",
    "print(aligned_model(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0988133550, -0.0700098723, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039329, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146526, -0.1857692599],\n",
      "        [-0.0992155895, -0.0657143146, -0.1859866083],\n",
      "        [-0.0967054814, -0.0699071437, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0988133550, -0.0700098723, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039329, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146526, -0.1857692599],\n",
      "        [-0.0992155895, -0.0657143146, -0.1859866083],\n",
      "        [-0.0967054814, -0.0699071437, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0988133550, -0.0700098649, -0.1872032136],\n",
      "        [-0.0984527767, -0.0642039329, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146451, -0.1857692599],\n",
      "        [-0.0992155895, -0.0657143220, -0.1859866083],\n",
      "        [-0.0967054814, -0.0699071437, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "I am here\n",
      "tensor([[-0.0988133550, -0.0700098649, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039478, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146451, -0.1857692748],\n",
      "        [-0.0992155820, -0.0657143220, -0.1859866083],\n",
      "        [-0.0967054814, -0.0699071437, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0988133550, -0.0700098574, -0.1872031987],\n",
      "        [-0.0984527767, -0.0642039478, -0.1895425171],\n",
      "        [-0.0974958241, -0.0685146451, -0.1857692748],\n",
      "        [-0.0992155895, -0.0657143220, -0.1859866083],\n",
      "        [-0.0967054814, -0.0699071586, -0.1942999810]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model1 = GenericMLP(layer_sizes=(3072, 70, 60, 50, 40, 30, 3))\n",
    "model2 = GenericMLP(layer_sizes=(3072, 70, 60, 50, 40, 30, 3))\n",
    "model1.eval(), model2.eval()\n",
    "\n",
    "#print(model)\n",
    "\n",
    "#print(model2(records_flattened))\n",
    "print(model1(records_flattened))\n",
    "\n",
    "t2 = TopDownAlignmentMethod()\n",
    "permutation = np.arange(30)\n",
    "permutation[0] = 1\n",
    "permutation[1] = 0\n",
    "aligned_model1 = t2.align_layers(model1, sorted_idxs={'fc2': np.arange(70), 'fc3': np.arange(60), 'fc4': np.arange(50), \\\n",
    "    'fc5': np.arange(40), 'fc6': permutation})\n",
    "\n",
    "print(aligned_model1(records_flattened))\n",
    "\n",
    "aligned_model2 = t2.align_layers(model1, sorted_idxs={'fc2': np.random.permutation(70), 'fc3': np.random.permutation(60), \\\n",
    "    'fc4': np.random.permutation(50), 'fc5': np.random.permutation(40), 'fc6': np.random.permutation(30)})\n",
    "\n",
    "print(aligned_model2(records_flattened))\n",
    "\n",
    "aligned_model3 = TopDownWeightMatchingBasedAlignment(HungarianAlgorithmMatching()).align_layers(model1, model2)\n",
    "\n",
    "print(aligned_model3(records_flattened))\n",
    "\n",
    "aligned_model4 = TopDownActivationMatchingBasedAlignment(HungarianAlgorithmMatching()).align_layers(model1, model2, records=records_flattened)\n",
    "\n",
    "print(aligned_model4(records_flattened))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "I am here\n",
      "tensor([[ 0.0742715746,  0.1782563925,  0.0600745454],\n",
      "        [ 0.1083160043,  0.1627133936,  0.0658590943],\n",
      "        [ 0.1604916006,  0.2382882386, -0.0252837539],\n",
      "        [ 0.0827141851,  0.1198018417,  0.0181518570],\n",
      "        [ 0.1977791339,  0.2047205120, -0.0100919977]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([-0.0216782764, -0.0295759179, -0.0382286869,  0.0249514319],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tensor([-0.0282329880, -0.0384886377,  0.0438725203,  0.0271678474],\n",
      "       grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "model1, model2 = CNNLarge(3), CNNLarge(3)\n",
    "model1.eval(), model2.eval()\n",
    "\n",
    "print(model1(records))\n",
    "\n",
    "t4 = TopDownWeightMatchingBasedAlignment(HungarianAlgorithmMatching())\n",
    "aligned_model1 = t4.align_layers(model1, model2)\n",
    "\n",
    "print(aligned_model1(records))\n",
    "print(model1.fc2.linear.weight[0, :4])\n",
    "print(aligned_model1.fc2.linear.weight[0, :4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0742715672,  0.1782564372,  0.0600745715],\n",
      "        [ 0.1083159596,  0.1627133638,  0.0658591390],\n",
      "        [ 0.1604915261,  0.2382883430, -0.0252837017],\n",
      "        [ 0.0827141851,  0.1198017597,  0.0181517880],\n",
      "        [ 0.1977791786,  0.2047205120, -0.0100920647]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0742715448,  0.1782563180,  0.0600745678],\n",
      "        [ 0.1083159894,  0.1627133042,  0.0658590719],\n",
      "        [ 0.1604914963,  0.2382882386, -0.0252837762],\n",
      "        [ 0.0827142373,  0.1198018119,  0.0181519128],\n",
      "        [ 0.1977791637,  0.2047205418, -0.0100920461]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "Parameter containing:\n",
      "tensor([ 0.0931478292, -0.0902533308,  0.0397556275, -0.0434939526,\n",
      "        -0.0485915691, -0.0240835622, -0.0427407697,  0.0632729903,\n",
      "        -0.0219392069,  0.0875514373,  0.0263483208, -0.0178418867,\n",
      "        -0.0666954368, -0.1057328135, -0.0336851887, -0.1069289148,\n",
      "        -0.0213932134,  0.0018872782, -0.0074413321, -0.0567208417],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0018872782, -0.0219392069, -0.0240835622, -0.0336851887,\n",
      "        -0.0434939526, -0.0178418867,  0.0931478292, -0.0213932134,\n",
      "        -0.0666954368, -0.0427407697, -0.1069289148,  0.0397556275,\n",
      "        -0.1057328135,  0.0632729903, -0.0074413321, -0.0485915691,\n",
      "         0.0875514373, -0.0567208417,  0.0263483208, -0.0902533308],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "model1 = model = CNNLarge(3)\n",
    "model2 = model = CNNLarge(3)\n",
    "model1.eval(), model2.eval()\n",
    "\n",
    "#print(model)\n",
    "\n",
    "print(model1(records))\n",
    "\n",
    "aligned_model1 = TopDownActivationMatchingBasedAlignment(HungarianAlgorithmMatching()).align_layers(model1, model2, records=records)\n",
    "\n",
    "print(aligned_model1(records))\n",
    "print(model1.conv1[0].bias)\n",
    "print(aligned_model1.conv1[0].bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "bb0479fa05b08352fe2aa87e9f2e7db977f009780f5c2b49d40bc77b6557af15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
