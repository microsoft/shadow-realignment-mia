# Architecture.
architecture=cnn-large-test-mia
# Data transformation.
transform=normalize
# Optimization parameters.
optimizer=sgd
batch_size=64
learning_rate=0.01
momentum=0.9
weight_decay=0.0
max_num_epochs=1
num_epochs_patience=1
# The target model will be trained on 5000 records, computed as 1/4 of 14000 + 10000 (size of CIFAR10 test set) - 2x2000 records.
dataset_size=14000
num_val_records_shadow_model=2000
num_meta_model_test_records=500
num_meta_model_val_records=500

