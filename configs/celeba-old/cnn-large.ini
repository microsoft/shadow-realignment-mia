# Architecture.
dataset=celeba-old
architecture=cnn-large
# Data transformation.
transform=resize_normalize
# Optimization parameters.
optimizer=sgd
batch_size=64
learning_rate=0.01
momentum=0.9
weight_decay=0.0
max_num_epochs=100
num_epochs_patience=5
min_learning_rate=1e-4
num_val_records=2000
eval_train=False
